# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_count(boot_responses, j) #' returns response count for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) %>% #outputs MAUI rank table of bootstrap sample responses
item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('item_frequencies', 'participant_scores')
names(score_frames) <- c('score_frequencies', 'participant_scores')
write_csv(score_frames[[1]], 'data/dissertation score frequencies.csv')
write_csv(score_frames[[2]], 'data/dissertation participant scores.csv')
library(foreach)
library(tidyverse)
library(readxl)
source('code/model fitting functions.R')
#####
# Set up/load files
item_scores <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
View(item_score_frequencies)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_count(boot_responses, j) #' returns response count for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #%>% #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
View(score_frames)
View(score_frames[[1]])
write_csv(score_frames[[1]], 'data/dissertation score frequencies.csv')
library(foreach)
library(tidyverse)
library(readxl)
source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
View(item_score_frequencies)
#library(matrixStats)
#library(data.table)
#library(reshape2)
#library(openxlsx)
#library(lazyeval)
#library(plyr)
#library(dplyr)
#library(tidyr)
library(tidyverse)
library(ggplot2)
library(plotly)
setwd("C:/Users/Zach/Documents/SpiderOak Hive/Research/Garrett - Time-stamping/MAUI-Bootstrapping")
source("density plot functions.R")
# Get Full List from entire study
# rows are all participant X response for a given item
fullList <- read.csv("Profiles_Tall99_170318.csv", header = TRUE)
# transforms for rest of file, adjust for raw variable names here
useList <- fullList %>%
transmute(partID = PartID,
resp = Std,
type = Type,
ord = ItemOrd,
itemID = paste(Type, ItemOrd, sep = "."))
# calculates frequency by grouping
counts <- useList %>%
group_by(itemID, resp) %>%
summarize(freq = n(), type = first(type), ord = first(ord))
# generates summary stats from master and freq count
summary <- sumStats(useList, counts)
# calculates UIs
UIs <- calcUIs(counts, summary)
# calculates UIs w/ ranks for density calcs
UIswRank <- UIs %>% arrange(itemID, -freq) %>% group_by(itemID) %>% mutate(cum = cumsum(freq), rank = dense_rank(-freq))
UIswDens <- calcDensity(UIswRank)
allwUIs <- left_join(UIswRank, UIswDens, by = c("itemID" = "itemID", "rank" = "rank", "type" = "type",
"ord" = "ord", "resps" = "resps", "N" = "N", "most" = "most"))
# UI df for histograms
uiHist <- allwUIs %>%
select(one_of(c('itemID', 'resp', 'UI', 'MAUI', 'normlnMAUI', 'midDens'))) %>%
right_join(useList, by = c('itemID', 'resp'))
#UI tall df for histograms
uiSuperTall <- uiHist %>%
select(-resp) %>%
gather(key = scale, value = value, UI, MAUI, normlnMAUI, midDens)
# simple histogram
p <- uiHist %>%
filter(itemID == 2.2) %>%
plot_ly(.) %>%
add_histogram(x = ~UI, name = 'UI') %>%
add_histogram(x = ~MAUI, name = 'MAUI') %>%
add_histogram(x = ~normlnMAUI, name = 'normMAUI') %>%
add_histogram(x = ~midDens, name = 'midDens')
print(p)
#histogram with density overlay
hist <- ggplot(uiHist, aes(UI)) +
geom_histogram(aes(y = ..density..), alpha = 0.7, fill = "#333333") +
geom_density(fill = "#ff4d4d", alpha = 0.5) +
theme(panel.background = element_rect(fill = '#ffffff')) +
ggtitle("Density with Histogram overlay")
print(hist)
#multiple overlaid histograms
hist <- uiSuperTall %>%
filter(itemID == 3.3) %>%
ggplot(aes(value, fill = scale)) +
#geom_histogram(aes(y = ..density..), alpha = 0.7, fill = "#333333") +
geom_density(alpha = 0.5) #+
#theme(panel.background = element_rect(fill = '#ffffff')) +
#ggtitle("item 1.1")
hist <- ggplotly(hist)
print(hist)
hist2d <- ggplot(uiHist, aes(MAUI)) +
geom_histogram() +
facet_grid(itemID ~ .)
hist2d <- ggplotly(hist2d)
print(hist2d)
# 3d cum density plot of answers
g <- plot_ly(UIswDens, x = ~normRank, y = ~most, z = ~cumDens, type = 'scatter3d', mode = 'lines', color = ~type)
print(g)
# 2d response histograms
hist2d <- ggplot(allwUIs, aes(midDens)) +
geom_histogram() +
facet_grid(itemID ~ .)
hist2d <- ggplotly(hist2d)
print(hist2d)
View(UIswDens)
library(foreach)
library(tidyverse)
library(readxl)
source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
items <- unique(item_scores$TypeItem) #item names from frame
library(foreach)
library(tidyverse)
library(readxl)
source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
items <- unique(item_scores$TypeItem) #item names from frame
items <- unique(item_score_frequencies$TypeItem) #item names from frame
View(item_score_frequencies)
samples <- unique(item_score_frequencies$sample_size) #sample sizes from frame
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
item_score_frequencies %>%
filter(TypeItem == i & sample_size == j) %>%
group_by(count) %>%
summarise(frequency = n()) %>%
ungroup()
}
View(item_densities)
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
item_score_frequencies %>%
filter(TypeItem == i & sample_size == j) %>%
mutate(rank = rank(count))
}
View(item_densities)
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
item_score_frequencies %>%
filter(TypeItem == i & sample_size == j) %>%
mutate(rank = rank(-count))
}
View(item_densities)
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
max_cumsum <- max(hold$cumsum)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_cumsum = cumsum/max_cumsum)
}
View(item_densities)
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(norm_rank = (rank-0.5)/max_rank)
}
View(item_densities)
item_density_plot <- ggplot(data = item_densities) +
geom_line(mapping = aes(x=norm_rank, y=MAUI)) +
facet_grid(sample_size ~ TypeItem)
item_density_plot
print(item_density_plot)
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank)
}
UI95_item_density_plot <- ggplot(data = item_densities) +
geom_line(mapping = aes(x=norm_rank, y=UI95)) +
facet_grid(sample_size ~ TypeItem)
print(UI95_item_density_plot)
View(participant_scores)
MAUI_participant_hist <- ggplot(data = participant_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
print(MAUI_participant_hist)
UI95_participant_hist <- ggplot(data = participant_scores, aes(sum_UI95)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
print(UI95_participant_hist)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
View(boot_parts)
write_csv(boot_parts, 'data/bootstrapped participant IDs.csv')
participant_ids <- read_csv('data/bootstrapped participant ids.csv')
participant_ids <- read_csv('data/bootstrapped participant ids.csv')
target_ids <- filter(participant_ids, sample_size == 100)
library(foreach)
library(tidyverse)
library(readxl)
#source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
participant_ids <- read_csv('data/bootstrapped participant ids.csv')
target_ids <- filter(participant_ids, sample_size == 100)
items <- unique(item_score_frequencies$TypeItem) #item names from frame
samples <- unique(item_score_frequencies$sample_size) #sample sizes from frame
View(participant_scores)
target_ids <- filter(participant_ids, sample_size == 100) %>% select(-sample_size)
target_scores <- filter(participant_scores, partID %in% target_ids)
View(target_scores)
target_scores <- filter(participant_scores, partID %in% target_ids$partID)
View(target_scores)
MAUI_target_hist <- ggplot(data = target_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
UI95_target_hist <- ggplot(data = target_scores, aes(sum_UI95)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
print(UI95_target_hist)
print(MAUI_target_hist)
View(target_scores)
target_scores_summary <- target_scores %>%
group_by(TypeItem, sample_size) %>%
summarise(sum_MAUI_mean = mean(sum_MAUI),
sum_MAUI_var = var(sum_MAUI),
avg_MAUI_mean = mean(avg_MAUI),
avg_MAUI_var = var(avg_MAUI),
sum_UI95_mean = mean(sum_UI95),
sum_UI95_var = var(sum_UI95),
avg_UI95_mean = mean(avg_UI95),
avg_UI95_var = var(avg_UI95))
View(target_scores_summary)
library(foreach)
library(tidyverse)
library(readxl)
#source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
participant_ids <- read_csv('data/bootstrapped participant ids.csv')
target_ids <- filter(participant_ids, sample_size == 100)
target_scores <- filter(participant_scores, partID %in% target_ids$partID)
items <- unique(item_score_frequencies$TypeItem) #item names from frame
samples <- unique(item_score_frequencies$sample_size) #sample sizes from frame
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank)
}
View(item_densities)
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_mass = cumsum - (mass/2))
}
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
ans <- max(cumsum)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_mass = cumsum/ans)
}
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
ans <- max(cumsum)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_mass = cumsum/ans)
}
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
#ans <- max(cumsum)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_mass = cumsum/max(cumsum))
}
UI95_item_density_plot <- ggplot(data = item_densities) +
geom_line(mapping = aes(x=norm_mass, y=UI95)) +
facet_grid(sample_size ~ TypeItem)
print(UI95_item_density_plot)
MAUI_step_plot <- ggplot(data = item_densities) +
geom_step(mapping = aes(x=norm_mass, y=MAUI), direction='vh') +
facet_grid(sample_size ~ TypeItem)
print(MAUI_step_plot)
UI95_step_plot <- ggplot(data = item_densities) +
geom_step(mapping = aes(x=norm_mass, y=UI95), direction='vh') +
facet_grid(sample_size ~ TypeItem)
print(UI95_step_plot)
UI95_step_plot <- ggplot(data = item_densities) +
geom_step(mapping = aes(x=norm_mass, y=UI95)) +
facet_grid(sample_size ~ TypeItem)
print(UI95_step_plot)
MAUI_item_hist <- qplot(MAUI, data=item_densities, weight=mass, geom="histogram") +
facet_grid(sample_size ~ TypeItem)
print(MAUI_item_hist)

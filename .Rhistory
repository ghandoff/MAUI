library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
#'This codelet operates on a single item
#' input file
#' first column must be named 'participant' and holds participant IDs
#' secon column must be named 'response' and holds the standardized responses
raw <- read_csv('data/test data.csv')
raw$response <- str_replace_all(raw$response, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
n <- length(unique(raw$participant)) #' calculates number of participants
UI_thresh <- .95 #' the 'old UI' threshhold, default at 95%
top_x <- 5 #' how many of the highest MAUI scores to use for the top X score
#' freq_table holds standardized responses and the frequency they occur in the item (i.e. the size of the fruit)
freq_table <- raw %>%
group_by(response) %>%
summarise(frequency = n())
#' mass_table has a bunch of intermediate calculations, and also the scores
#' 'frequency' is how often that response occurs in the item (fruit size)
#' 'count' is how many responses are of that frequency (i.e. how many fruits are on that level)
#' 'mass' is frequency*count (i.e. the total mass of fruit on that level)
#' 'cum_mass' is the mass of responses on that level and below
#' MAUI is calculated from the cum_mass of the level below + half of the current level mass
#' UI is calculated in the standard way from n and UI_thresh
mass_table <- freq_table %>%
group_by(frequency) %>%
summarise(count = n()) %>%
arrange(desc(frequency)) %>%
mutate(mass = frequency*count) %>%
mutate(cum_mass = cumsum(mass)) %>%
mutate(MAUI = (cum_mass - mass/2)/max(cum_mass),
UI = 1 - frequency/n,
norm_rank = (rank(cum_mass) - .5)/nrow(mass_table))
#' appends MAUI and UI to freq_table
freq_table <- freq_table %>%
left_join(select(mass_table, -count, -mass, -cum_mass))
#' p_response_scores is the original data with MAUI and UI scores appended to each response
p_response_scores <- raw %>%
left_join(select(freq_table, -frequency))
#' calculates the top X score to append below
top_x_scores <- p_response_scores %>%
select(-UI) %>%
arrange(participant, desc(MAUI)) %>%
group_by(participant) %>%
slice(seq_len(top_x)) %>%
summarise(top_x_MAUI = sum(MAUI))
#' p_scores is a summary for each participant
#' current reports fluency, the sum of all MAUI scores and the sum of all UI scores
#' But very adaptable for new scores!
p_scores <- p_response_scores %>%
mutate(UI = if_else(UI >= UI_thresh, 1, 0)) %>%
group_by(participant) %>%
summarise(fluency = n(),
MAUI_sum = sum(MAUI),
UI_sum = sum(UI)) %>%
left_join(top_x_scores)
mass_graph <- ggplot(mass_table) +
geom_line(aes(norm_rank, MAUI), color = 'blue') +
geom_line(aes(norm_rank, UI), color = 'red')
plot(mass_graph)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
#'This codelet operates on a single item
#' input file
#' first column must be named 'participant' and holds participant IDs
#' secon column must be named 'response' and holds the standardized responses
raw <- read_csv('data/test data.csv')
raw$response <- str_replace_all(raw$response, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
n <- length(unique(raw$participant)) #' calculates number of participants
UI_thresh <- .95 #' the 'old UI' threshhold, default at 95%
top_x <- 5 #' how many of the highest MAUI scores to use for the top X score
#' freq_table holds standardized responses and the frequency they occur in the item (i.e. the size of the fruit)
freq_table <- raw %>%
group_by(response) %>%
summarise(frequency = n())
#' mass_table has a bunch of intermediate calculations, and also the scores
#' 'frequency' is how often that response occurs in the item (fruit size)
#' 'count' is how many responses are of that frequency (i.e. how many fruits are on that level)
#' 'mass' is frequency*count (i.e. the total mass of fruit on that level)
#' 'cum_mass' is the mass of responses on that level and below
#' MAUI is calculated from the cum_mass of the level below + half of the current level mass
#' UI is calculated in the standard way from n and UI_thresh
mass_table <- freq_table %>%
group_by(frequency) %>%
summarise(count = n()) %>%
arrange(desc(frequency)) %>%
mutate(mass = frequency*count) %>%
mutate(cum_mass = cumsum(mass)) %>%
mutate(MAUI = (cum_mass - mass/2)/max(cum_mass),
UI = 1 - frequency/n,
norm_rank = (rank(cum_mass) - .5)/nrow(.))
#' appends MAUI and UI to freq_table
freq_table <- freq_table %>%
left_join(select(mass_table, -count, -mass, -cum_mass))
#' p_response_scores is the original data with MAUI and UI scores appended to each response
p_response_scores <- raw %>%
left_join(select(freq_table, -frequency))
#' calculates the top X score to append below
top_x_scores <- p_response_scores %>%
select(-UI) %>%
arrange(participant, desc(MAUI)) %>%
group_by(participant) %>%
slice(seq_len(top_x)) %>%
summarise(top_x_MAUI = sum(MAUI))
#' p_scores is a summary for each participant
#' current reports fluency, the sum of all MAUI scores and the sum of all UI scores
#' But very adaptable for new scores!
p_scores <- p_response_scores %>%
mutate(UI = if_else(UI >= UI_thresh, 1, 0)) %>%
group_by(participant) %>%
summarise(fluency = n(),
MAUI_sum = sum(MAUI),
UI_sum = sum(UI)) %>%
left_join(top_x_scores)
mass_graph <- ggplot(mass_table) +
geom_line(aes(norm_rank, MAUI), color = 'blue') +
geom_line(aes(norm_rank, UI), color = 'red')
plot(mass_graph)
View(mass_table)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
write.csv(score_frames[[1]], 'data/score_frequencies.csv')
write.csv(score_frames[[2]], 'data/participant_scores.csv')
library(tidyverse)
library(ggplot2)
data <- read_csv('data/score_frequencies.csv') %>%
select(-X1)
mass_graph <- ggplot(data) +
geom_line(aes(norm_rank, MAUI), color = 'blue') +
geom_line(aes(norm_rank, UI), color = 'red') +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(mass_graph)
data <- read_csv('data/participant_scores.csv')
p_scores <- read_csv('data/participant_scores.csv') %>%
select(-X1)
View(p_scores)
p_UI_hist <- ggplot(p_scores, aes(UI)) +
geom_histogram(color = 'red') +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(p_UI_hist)
p_UI_hist <- ggplot(p_scores, aes(sum_UI95)) +
geom_histogram(color = 'red') +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(p_UI_hist)
p_MAUI_hist <- ggplot(p_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(p_MAUI_hist)
p_topMAUI_hist <- ggplot(p_scores, aes(top5_MAUI)) +
geom_histogram() +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(p_topMAUI_hist)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
score_frames[[1]]
View(score_frames[[1]])
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
View(score_frames)
View(score_frames[[2]])
View(boot_participant_scores)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores, [[3]] is just the target population scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
View(boot_parts)
View(target_parts)
View(target_sample)
score_frames[[3]] <- score_frames[[2]] %>%
filter(partID %in% target_sample)
View(score_frames[[3]])
df <- score_frames[[2]] %>%
filter(partID %in% target_sample)
df <- score_frames[[2]] %>%
filter(partID %in% target_sample$partID)
View(df)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores, [[3]] is just the target population scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
score_frames[[3]] <- score_frames[[2]] %>%
filter(partID %in% target_sample$partID)
names(score_frames) <- c('score_frequencies', 'participant_scores', 'target_participant_scores')
write.csv(score_frames[[1]], 'data/score_frequencies.csv')
write.csv(score_frames[[2]], 'data/participant_scores.csv')
write.csv(score_frames[[3]], 'data/target_participant_scores.csv')
target_scores <- read_csv('data/target_participant_scores.csv') %>%
select(-X1)
View(target_scores)
target_scores <- read_csv('data/target_participant_scores.csv') %>%
select(-X1)
View(target_scores)
target_UI_hist <- ggplot(target_scores, aes(sum_UI95)) +
geom_histogram() +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
target_MAUI_hist <- ggplot(target_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
target_topMAUI_hist <- ggplot(target_scores, aes(top5_MAUI)) +
geom_histogram() +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size))
plot(target_UI_hist)
plot(target_MAUI_hist)
dd <- data.frame(
predicted = rnorm(720, mean = 2, sd = 2),
state = rep(c("A", "B", "C"), each = 240)
)
View(dd)
grid <- with(dd, seq(min(predicted), max(predicted), length = 100))
normaldens <- ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
normal_curve = dnorm(grid, mean(df$predicted), sd(df$predicted)) * length(df$predicted) * binwidth
)
})
library(tidyverse)
normaldens <- ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
normal_curve = dnorm(grid, mean(df$predicted), sd(df$predicted)) * length(df$predicted) * binwidth
)
})
normaldens <- do(group_by(dd, state), data.frame(predicted = grid,
normal_curve = dnorm(grid, mean(df$predicted), sd(df$predicted))*length(df$predicted)*binwidth
))
target_UI_hist <- ggplot(target_scores, aes(sum_UI95)) +
facet_grid(rows = vars(TypeItem), cols = vars(sample_size)) +
geom_density()
plot(target_UI_hist)
library(plyr)
normaldens <- ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
normal_curve = dnorm(grid, mean(df$predicted), sd(df$predicted)) * length(df$predicted) * binwidth
)
})
binwidth <- .5
normaldens <- ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
normal_curve = dnorm(grid, mean(df$predicted), sd(df$predicted)) * length(df$predicted) * binwidth
)
})
View(normaldens)

e [label = '@@5']
subgraph{
rank = same; d; f; g; e;
}
node [shape = 'oval']
h [label = '@@8']
node [shape = 'circle']
i [label = '@@9']
subgraph {
rank = same; h; i;
}
# edge definitions with the node IDs
a -> c [dir = 'back']
b -> c [dir = 'back']
c -> {f g}
d -> f
f -> h
e -> g
g -> h
i -> h
}
[1]: 'Parent Science<br>Background (Education & Occupation)'
[2]: 'Parent AttitudeAbout Science (Score)'
[3]: 'Parent Science Interest & Expertise'
[4]: 'e@_1'
[5]: 'e<SUB>2</SUB>'
[6]: 'Child Systematic Gear Exploration'
[7]: 'Parent Explanatory Talk at Exhibit'
[8]: 'Child Causal Thinking'
[9]: 'e<SUB>3</SUB>'
")
grViz("
digraph a_nice_graph {
graph [layout = dot,
rankdir = LR]
# node definitions with substituted label text
node [shape = 'square']
a [label = 'Parent Science\\nBackground\\n(Education & Occupation)']
b [label = 'Parent\\nAttitude About\\nScience (Score)']
node [shape = 'oval']
c [label = '@@3']
node [shape = 'circle']
d [label = 'e@_{1}']
node [shape = 'square']
f [label = '@@6']
g [label = '@@7']
node [shape = 'circle']
e [label = '@@5']
subgraph{
rank = same; d; f; g; e;
}
node [shape = 'oval']
h [label = '@@8']
node [shape = 'circle']
i [label = '@@9']
subgraph {
rank = same; h; i;
}
# edge definitions with the node IDs
a -> c [dir = 'back', label = 'lam@_{1}]
b -> c [dir = 'back']
c -> {f g}
d -> f
f -> h
e -> g
g -> h
i -> h
}
[3]: 'Parent Science Interest & Expertise'
[4]: 'e@_1'
[5]: 'e<SUB>2</SUB>'
[6]: 'Child Systematic Gear Exploration'
[7]: 'Parent Explanatory Talk at Exhibit'
[8]: 'Child Causal Thinking'
[9]: 'e<SUB>3</SUB>'
")
grViz("
digraph a_nice_graph {
graph [layout = dot,
rankdir = LR]
# node definitions with substituted label text
node [shape = 'square']
a [label = 'Parent Science\\nBackground\\n(Education & Occupation)']
b [label = 'Parent\\nAttitude About\\nScience (Score)']
node [shape = 'oval']
c [label = '@@3']
node [shape = 'circle']
d [label = 'e@_{1}']
node [shape = 'square']
f [label = '@@6']
g [label = '@@7']
node [shape = 'circle']
e [label = '@@5']
subgraph{
rank = same; d; f; g; e;
}
node [shape = 'oval']
h [label = '@@8']
node [shape = 'circle']
i [label = '@@9']
subgraph {
rank = same; h; i;
}
# edge definitions with the node IDs
a -> c [dir = 'back', label = 'lam@_{1}]
b -> c [dir = 'back']
c -> {f g}
d -> f
f -> h
e -> g
g -> h
i -> h
}
[1]: ''
[2]: ''
[3]: 'Parent Science Interest & Expertise'
[4]: 'e@_1'
[5]: 'e<SUB>2</SUB>'
[6]: 'Child Systematic Gear Exploration'
[7]: 'Parent Explanatory Talk at Exhibit'
[8]: 'Child Causal Thinking'
[9]: 'e<SUB>3</SUB>'
")
grViz("
digraph a_nice_graph {
graph [layout = dot,
rankdir = LR]
# node definitions with substituted label text
node [shape = 'square']
a [label = 'Parent Science\\nBackground\\n(Education & Occupation)']
b [label = 'Parent\\nAttitude About\\nScience (Score)']
node [shape = 'oval']
c [label = '@@3']
node [shape = 'circle']
d [label = 'e@_{1}']
node [shape = 'square']
f [label = '@@6']
g [label = '@@7']
node [shape = 'circle']
e [label = '@@5']
subgraph{
rank = same; d; f; g; e;
}
node [shape = 'oval']
h [label = '@@8']
node [shape = 'circle']
i [label = '@@9']
subgraph {
rank = same; h; i;
}
# edge definitions with the node IDs
a -> c [label = 'lam@_{1},
dir = 'back']
b -> c [dir = 'back']
c -> {f g}
d -> f
f -> h
e -> g
g -> h
i -> h
}
[1]: ''
[2]: ''
[3]: 'Parent Science Interest & Expertise'
[4]: 'e@_1'
[5]: 'e<SUB>2</SUB>'
[6]: 'Child Systematic Gear Exploration'
[7]: 'Parent Explanatory Talk at Exhibit'
[8]: 'Child Causal Thinking'
[9]: 'e<SUB>3</SUB>'
")
library(foreach)
library(tidyverse)
library(readxl)
#source('code/model fitting functions.R')
#####
# Set up/load files
item_score_frequencies <- read_csv('data/dissertation score frequencies.csv')
participant_scores <- read_csv('data/dissertation participant scores.csv')
participant_ids <- read_csv('data/bootstrapped participant ids.csv')
target_ids <- filter(participant_ids, sample_size == 100)
target_scores <- filter(participant_scores, partID %in% target_ids$partID)
items <- unique(item_score_frequencies$TypeItem) #item names from frame
samples <- unique(item_score_frequencies$sample_size) #sample sizes from frame
#####
# makes calcs for and graphs density plots
item_densities <- foreach(i=items, .combine='rbind') %:%
foreach(j=samples, .combine='rbind') %do% {
hold <- item_score_frequencies %>%
filter(TypeItem == i & sample_size == j)
max_rank <- nrow(hold)
#ans <- max(cumsum)
densities <- hold %>%
mutate(rank = rank(-count)) %>%
mutate(UI95 = case_when(pct_giving <= .05 ~ 1,
TRUE ~ 0)) %>%
mutate(norm_rank = (rank-0.5)/max_rank,
norm_mass = cumsum/max(cumsum))
}
MAUI_item_density_plot <- ggplot(data = item_densities) +
geom_line(mapping = aes(x=norm_rank, y=MAUI)) +
facet_grid(sample_size ~ TypeItem)
UI95_item_density_plot <- ggplot(data = item_densities) +
geom_line(mapping = aes(x=norm_mass, y=UI95)) +
facet_grid(sample_size ~ TypeItem)
MAUI_step_plot <- ggplot(data = item_densities) +
geom_step(mapping = aes(x=norm_mass, y=MAUI), direction='vh') +
facet_grid(sample_size ~ TypeItem)
UI95_step_plot <- ggplot(data = item_densities) +
geom_step(mapping = aes(x=norm_mass, y=UI95)) +
facet_grid(sample_size ~ TypeItem)
MAUI_item_hist <- qplot(MAUI, data=item_densities, weight=mass, geom="histogram") +
facet_grid(sample_size ~ TypeItem)
# UI95_item_hist is basically identical to the step plot, as it only takes 2 values
#####
# makes calcs for and graphs participant score histograms
MAUI_participant_hist <- ggplot(data = participant_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
UI95_participant_hist <- ggplot(data = participant_scores, aes(sum_UI95)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
#####
# target sample vizualizations
MAUI_target_hist <- ggplot(data = target_scores, aes(sum_MAUI)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
UI95_target_hist <- ggplot(data = target_scores, aes(sum_UI95)) +
geom_histogram() +
facet_grid(sample_size ~ TypeItem)
target_scores_summary <- target_scores %>%
group_by(TypeItem, sample_size) %>%
summarise(sum_MAUI_mean = mean(sum_MAUI),
sum_MAUI_var = var(sum_MAUI),
avg_MAUI_mean = mean(avg_MAUI),
avg_MAUI_var = var(avg_MAUI),
sum_UI95_mean = mean(sum_UI95),
sum_UI95_var = var(sum_UI95),
avg_UI95_mean = mean(avg_UI95),
avg_UI95_var = var(avg_UI95))
plot(MAUI_participant_hist)
plot(UI95_participant_hist)
MAUI_participant_hist <- ggplot(data = participant_scores, aes(sum_MAUI)) +
geom_histogram(binwidth=2) +
facet_grid(sample_size ~ TypeItem)
UI95_participant_hist <- ggplot(data = participant_scores, aes(sum_UI95)) +
geom_histogram(binwidth=2) +
facet_grid(sample_size ~ TypeItem)
plot(MAUI_participant_hist)
MAUI_participant_hist <- ggplot(data = participant_scores, aes(sum_MAUI)) +
geom_histogram(binwidth=2) +
stat_function(fun=dnorm,
color="red",
args=list(mean=mean(participant_scores$sum_MAUI),
sd=sd(participant_scores$sum_MAUI))) +
facet_grid(sample_size ~ TypeItem)
plot(MAUI_participant_hist)
dd <- data.frame(
predicted = rnorm(72, mean = 2, sd = 2),
state = rep(c("A", "B", "C"), each = 24)
)
View(dd)
View(participant_scores)
grid <- with(dd, seq(min(predicted), max(predicted), length = 100))
normaldens <- ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
density = dnorm(grid, mean(df$predicted), sd(df$predicted))
)
})
grid <- with(dd, seq(min(predicted), max(predicted), length = 100))
normaldens <- dd %>%
group_by(state) %>%
mutate(predicted = grid,
density = dnorm(grid, mean(df$predicted), sd(df$predicted))
)
normaldens <- dd %>%
group_by(state) %>%
mutate(density = dnorm(grid, mean(df$predicted), sd(df$predicted))
)
dd <- cbind(dd, grid)
normaldens <- dd %>%
group_by(state) %>%
mutate(density = dnorm(grid, mean(grid), sd(grid))
)
View(grid)
install.packages("plyr")
normaldens <- plyr::ddply(dd, "state", function(df) {
data.frame(
predicted = grid,
density = dnorm(grid, mean(df$predicted), sd(df$predicted))
)
})
View(normaldens)
install.packages("doParallel")
install.packages("writexl")
library(tidyverse)
data <- read_csv('data/score_frequencies.csv')
View(data)
data <- read_csv('data/score_frequencies.csv') %>%
select(-X1)
library(ggplot2)
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
#####
# Randomization for target & bootstrap samples
# Also sets up dfs with bootstrap participants & their responses
#' column of ID numbers in the target sample
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
#' P x item frame of those remaining
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
#' establishing participant list for scoring for loop
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
#####
# scoring functionality!
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_freq(boot_responses, j) #' returns response frequency for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')

i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
if (accuracies[1] == .99) {
t(c(elimination, 1))
} else {
t(c(elimination, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
View(results)
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(is.na(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
acc <- seq(from = .99, to = .90, by = -.01)
elim <- c(rep(NA, times = 10))
i <<- 1
round_sim(accuracies, elimination, i)
accuracies <<- acc
elimination <<- elim
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- i+1
i <- 1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim <- function(a, e, c) {
this_rnd <<- (sign(a - runif(10)) + 1)/2
# elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
# accuracies <<- a*this_rnd
elimination <<- as.integer(!is.na(e)) + ((1 - this_rnd) - sign(e))*(c+1)
accuracies <<- a*this_rnd
}
i <<- 1
accuracies <<- acc
elimination <<- elim
round_sim(accuracies, elimination, i)
i <- i+1
as.integer(!is.na(elimination)) + ((1 - this_rnd) - sign(elimination))*(c+1)
as.integer(!is.na(elimination)) + ((1 - this_rnd) - sign(elimination))*(i+1)
as.integer(!is.na(elimination))
round_sim <- function(a, e, c) {
this_rnd <<- (sign(a - runif(10)) + 1)/2
# elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
# accuracies <<- a*this_rnd
elimination <<- as.integer(!is.na(e)) + ((1 - this_rnd) - as.integer(!is.na(e)))*(c+1)
accuracies <<- a*this_rnd
}
accuracies <<- acc
elimination <<- elim
i <<- 1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
round_sim(accuracies, elimination, i)
i <- i+1
acc <- seq(from = .99, to = .90, by = -.01)
elim <- c(rep(0, times = 10))
results <- data.frame()
#accuracies <- acc
#elimination <- elim
round_sim <- function(a, e, c) {
this_rnd <- (sign(a - runif(10)) + 1)/2
# elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
# accuracies <<- a*this_rnd
elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
accuracies <<- a*this_rnd
}
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
if (accuracies[1] == .99) {
t(c(elimination, 1))
} else {
t(c(elimination, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
View(results)
res2 <- mutate_all(results, . == 0, NA)
res2 <- mutate_all(results, var == 0, NA)
res2 <- mutate_all(results, replace(var, var == 0, NA))
res2 <- mutate_all(results, replace(. == 0, NA))
res2 <- mutate_all(results, . = replace(. == 0, NA))
res2 <- mutate_all(~ replace(. == 0, NA))
res2 <- mutate_all(results, ~ replace(. == 0, NA))
res2 <- results %>% replace(. == 0, NA)
View(res2)
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
if (accuracies[1] == .99) {
t(c(replace(elimination, . == 0, NA), 1))
} else {
t(c(elimination, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
final <- elimination %>%
replace(. == 0, NA)
if (accuracies[1] == .99) {
t(c(elimination, 1))
} else {
t(c(elimination, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
View(results)
results <- data.frame()
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
typeof(elimination)
final <- elimination %>%
replace(. == 0, NA)
typeof(final)
final
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
final <- elimination %>%
replace(. == 0, NA)
if (accuracies[1] == .99) {
t(c(final, 1))
} else {
t(c(final, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
View(results)
library(tidyverse)
acc <- seq(from = .99, to = .90, by = -.01)
elim <- c(rep(0, times = 10))
results <- data.frame()
#accuracies <- acc
#elimination <- elim
round_sim <- function(a, e, c) {
this_rnd <- (sign(a - runif(10)) + 1)/2
# elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
# accuracies <<- a*this_rnd
elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
accuracies <<- a*this_rnd
}
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
final <- elimination %>%
replace(. == 0, NA)
if (accuracies[1] == .99) {
t(c(final, 1))
} else {
t(c(final, 0))
}
}
for(k in 1:10) {
results <- rbind(results, sim_calc())
}
library(tidyverse)
acc <- seq(from = .99, to = .90, by = -.01)
elim <- c(rep(0, times = 10))
results <- data.frame()
#accuracies <- acc
#elimination <- elim
round_sim <- function(a, e, c) {
this_rnd <- (sign(a - runif(10)) + 1)/2
# elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
# accuracies <<- a*this_rnd
elimination <<- e + ((1 - this_rnd) - sign(e))*(c+1)
accuracies <<- a*this_rnd
}
sim_calc <- function() {
accuracies <<- acc
elimination <<- elim
i <<- 1
while (accuracies[1] == .99 & sum(sign(elimination)) != 9) {
round_sim(accuracies, elimination, i)
i <<- i + 1
#assign(i, i+1, inherits = TRUE)
}
final <- elimination %>%
replace(. == 0, NA)
if (accuracies[1] == .99) {
t(c(final, 1))
} else {
t(c(final, 0))
}
}
for(k in 1:10000) {
results <- rbind(results, sim_calc())
}
View(results)
means <- summarise(results, mean(na.rm = TRUE))
means <- results %>% summarise(mean(na.rm = TRUE))
means <- results %>% summarise_all(mean(na.rm = TRUE))
means <- results %>% summarise_all(mean, na.rm = TRUE)
View(means)
res2 <- results %>%
mutate(sum(V1:V10))
res2 <- results %>%
mutate(sum = rowSums(.[1:10]))
View(res2)
res2 <- results %>%
mutate(sum = rowSums(.[1:10], na.rm = FALSE))
View(res2)
res2 <- results %>%
mutate(sum = rowSums(.[1:10], na.rm = TRUE))
View(res2)
res2 <- results %>%
mutate(sum = rowSums(sign(.[1:10]), na.rm = TRUE))
counts <- res2 %>%
group_by(sum) %>%
summarise(n = n())
View(counts)
weirds <- res2 %>%
filter(sum == 10) %>%
mutate(mtchs = V1 %in% .[2:10])
View(weirds)
weirds <- res2 %>%
filter(sum == 10) %>%
mutate(mtchs = which(V1 %in% .[2:10]))
which(LETTERS == "R")
which(LETTERRS == "R")
(LETTERS)
weirds <- res2 %>%
filter(sum == 10) %>%
mutate(mtchs = which(V1 == .[2:10]))
weirds <- res2 %>%
filter(sum == 10) %>%
mutate(mtchs = max())
weirds <- res2 %>%
filter(sum == 10) %>%
mutate(mtchs = max(.[2:10]))
View(weirds)
weirds <- res2 %>%
ungroup() %>%
filter(sum == 10) %>%
mutate(mtchs = which(V1 == .[2:10]))
weirds <- res2 %>%
ungroup() %>%
filter(sum == 10) %>%
mutate(mtchs = V1)
weirds <- res2 %>%
ungroup() %>%
filter(sum == 10) %>%
mutate(mtchs = which(V1))
weirds <- res2 %>%
ungroup() %>%
filter(sum == 10) %>%
mutate(mtchs = which(V1 == .[2:10]))
library(readxl)
write_csv(results, 'C:/Users/Zach/Documents/SpiderOak Hive/Puzzles/538 Spelling Bee/results.csv')
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
#'This codelet operates on a single item
#' input file
#' first column must be named 'participant' and holds participant IDs
#' secon column must be named 'response' and holds the standardized responses
raw <- read_csv('data/test data.csv')
n <- length(unique(raw$participant)) #' calculates number of participants
UI_thresh <- .95 #' the 'old UI' threshhold, default at 95%
top_x <- 5 #' how many of the highest MAUI scores to use for the top X score
#' freq_table holds standardized responses and the frequency they occur in the item (i.e. the size of the fruit)
freq_table <- raw %>%
group_by(response) %>%
summarise(frequency = n())
#' mass_table has a bunch of intermediate calculations, and also the scores
#' 'frequency' is how often that response occurs in the item (fruit size)
#' 'count' is how many responses are of that frequency (i.e. how many fruits are on that level)
#' 'mass' is frequency*count (i.e. the total mass of fruit on that level)
#' 'cum_mass' is the mass of responses on that level and below
#' MAUI is calculated from the cum_mass of the level below + half of the current level mass
#' UI is calculated in the standard way from n and UI_thresh
mass_table <- freq_table %>%
group_by(frequency) %>%
summarise(count = n()) %>%
arrange(desc(frequency)) %>%
mutate(mass = frequency*count) %>%
mutate(cum_mass = cumsum(mass)) %>%
mutate(MAUI = (cum_mass - mass/2)/max(cum_mass),
UI = 1 - frequency/n)
#' appends MAUI and UI to freq_table
freq_table <- freq_table %>%
left_join(select(mass_table, -count, -mass, -cum_mass))
#' p_response_scores is the original data with MAUI and UI scores appended to each response
p_response_scores <- raw %>%
left_join(select(freq_table, -frequency))
#' calculates the top X score to append below
top_x_scores <- p_response_scores %>%
select(-UI) %>%
arrange(participant, desc(MAUI)) %>%
group_by(participant) %>%
slice(seq_len(top_x)) %>%
summarise(top_x_MAUI = sum(MAUI))
#' p_scores is a summary for each participant
#' current reports fluency, the sum of all MAUI scores and the sum of all UI scores
#' But very adaptable for new scores!
p_scores <- p_response_scores %>%
mutate(UI = if_else(UI >= UI_thresh, 1, 0)) %>%
group_by(participant) %>%
summarise(fluency = n(),
MAUI_sum = sum(MAUI),
UI_sum = sum(UI)) %>%
left_join(top_x_scores)
View(p_response_scores)
View(mass_table)
mass_table <- freq_table %>%
group_by(frequency) %>%
summarise(count = n()) %>%
arrange(desc(frequency)) %>%
mutate(mass = frequency*count) %>%
mutate(cum_mass = cumsum(mass)) %>%
mutate(MAUI = (cum_mass - mass/2)/max(cum_mass),
UI = 1 - frequency/n,
norm_rank = rank(cum_mass)/nrow(mass_table))
mass_table <- freq_table %>%
group_by(frequency) %>%
summarise(count = n()) %>%
arrange(desc(frequency)) %>%
mutate(mass = frequency*count) %>%
mutate(cum_mass = cumsum(mass)) %>%
mutate(MAUI = (cum_mass - mass/2)/max(cum_mass),
UI = 1 - frequency/n,
norm_rank = (rank(cum_mass) - .5)/nrow(mass_table))
mass_graph <- ggplot(mass_table, aes(norm_rank, MAUI)) +
geom_line()
plot(mass_graph)
mass_graph <- ggplot(mass_table) +
geom_line(aes(norm_rank, MAUI))
plot(mass_graph)
mass_graph <- ggplot(mass_table) +
geom_line(norm_rank, MAUI, color = 'blue') +
geom_line(norm_rank, UI, color = 'red')
mass_graph <- ggplot(mass_table) +
geom_line(aes(norm_rank, MAUI), color = 'blue') +
geom_line(aes(norm_rank, UI), color = 'red')
plot(mass_graph)
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
library(openxlsx)
library(doParallel)
library(foreach)
library(tidyverse)
library(readxl)
#####
# Set up/load files
all_responses <- read_csv('data/Garrett Dissertation Data Answers Only.csv')
rm(lines)
rm(guentzel)
View(permin)
rm(permin)
View(all_responses)
all_responses$Std <- str_replace_all(all_responses$Std, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
#' input file
#' first column must be named 'participant' and holds participant IDs
#' secon column must be named 'response' and holds the standardized responses
raw <- read_csv('data/test data.csv')
View(raw)
raw$response <- str_replace_all(raw$response, "[^[:alnum:]]", " ") %>% #gets rid of non alphanumerics
tolower() #' turns everything to lowercase
rm(raw)
#' part_fluency_byitem is a P x item frame of fluency scores
#' crucially, NA means that the item was not completed by the P
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
set.seed(1729) #' 91 works too, but is less interesting.
source('code/bootstrapping subsample functions.R')
part_fluency_byitem <- std_to_fluency_table(all_responses, 'TypeItem', 'partID', 'Std')
View(part_fluency_byitem)
target_sample <- part_fluency_byitem %>%
na.omit() %>% #' ensures target sample did all 9 items
sample_n(100, replace = FALSE) %>%
select(partID)
View(target_sample)
remains_fluency_byitem <- part_fluency_byitem %>%
filter(!partID %in% target_sample$partID)
#' creates entire list of bootstrapped partIDs
#' note that not all of them have done all items
#' This line should be changed if we don't want each resample to be fully random
boot_parts <- foreach(i = seq(100, 800, by=100), .combine='rbind') %do% boot_nums(remains_fluency_byitem, i)
target_parts <- mutate(target_sample, n = 100)
remain_parts <- select(remains_fluency_byitem, partID) %>% setdiff(target_sample) %>% mutate(n = 1000)
boot_parts <- bind_rows(target_parts, boot_parts, remain_parts)
items <- names(part_fluency_byitem)[-1] #item names from frame
View(target_parts)
View(target_sample)
View(target_parts)
View(remains_fluency_byitem)
#' custom function to combine results from for loop
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
#' score_frames returns 2 lists
#' list 1 is a list of 10 response-level tibbles, 1 for each resample N
#' list 2 is a list of 10 participant-level tibbles, 1 for each resample N
score_frames <- foreach(i=seq(100, 1000, by=100), .combine='comb', .multicombine=TRUE,
.init=list(list(), list())) %dopar% {
ps_for_scoring <- bind_rows(target_sample, filter(boot_parts, n==i | n==100)) #participant IDs of holdout sample & resamples
boot_responses <- all_responses %>%
filter(partID %in% ps_for_scoring$partID) #'outputs all responses for all items on ps_for_scoring
boot_response_scores <- foreach(j = items, .combine='rbind') %do%
sort_count(boot_responses, j) #' returns response count for standardized responses in a single df
boot_ranks <- foreach(k = items, .combine='rbind') %do%
ranks(boot_response_scores, i, k) #outputs MAUI rank table of bootstrap sample responses
#item_calcs() #outputs MAUI rank table with 0 and 1 points
boot_response_scores <- foreach(l = items, .combine='rbind') %do%
append_scores(boot_response_scores, boot_ranks, l) %>% #' appends scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_response_freq <- boot_ranks %>%
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
boot_participant_scores <- foreach(m = items, .combine='rbind') %do%
p_score(boot_responses, boot_response_scores, m) %>% #' calculates participant scores
mutate(sample_size = as.integer(i)) #' adds indicator of bootstrap size; not important for public use tool
list(boot_response_freq, boot_participant_scores)
}
#' score_frames is a list of 2 tibbles
#' [[1]] is all the item scores, [[2]] is all the participant scores
score_frames[[1]] <- bind_rows(score_frames[[1]])
score_frames[[2]] <- bind_rows(score_frames[[2]])
names(score_frames) <- c('score_frequencies', 'participant_scores')
View(score_frames)
View(score_frames[1])
View(score_frames[[1]])
View(score_frames[[2]])
write.csv(score_frames[[1]], 'data/score_frequencies.csv')
write.csv(score_frames[[2]], 'data/participant_scores.csv')
